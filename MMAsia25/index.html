<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HD-Vision@MMAsia2025</title>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>
  <!-- Hero Section -->
  <section class="hero">
    <h1>International Workshop on Imaging, Processing, Perception, and Reasoning for High-Dimensional Visual Data</h1>
    <p class="subtitle">ACM Multimedia Asia 2025 Workshop</p>
    <p class="details">
      <i class="fa fa-calendar"></i> December 9 – 12, 2025 &nbsp;
      <i class="fa fa-map-marker"></i> Grand Millenium Hotel, Kuala Lumpur, Malaysia
    </p>
  </section>

  <!-- Main Content Container -->
  <div class="container">
    <!-- Summary Section -->
    <section id="summary">
      <h2>Summary</h2>
        <p>
          The International Workshop on Imaging, Processing, Perception, and Reasoning for High-Dimensional Visual Data (HD-Vision) addresses the rapidly evolving frontier of multimedia research, where visual information extends far beyond conventional 2D imagery. Emerging modalities such as light fields, event-based data, hyperspectral imaging, and multimodal sensor fusion encode rich spatial, temporal, angular, spectral, and cross-modal cues, unlocking unprecedented opportunities for comprehensive scene understanding.
        </p>
        <p>
          These modalities also introduce fundamental challenges in sensing, representation, and interpretation: the demand for novel acquisition techniques, efficient compression and transmission, robust neural reconstruction, and semantics-aware reasoning. HD-Vision aims to unite researchers from computational imaging, multimodal learning, and neural representation fields to confront these challenges and bridge the gap between foundational theory and practical deployment.
        </p>
        <p>
          The workshop serves as a collaborative platform to present state-of-the-art advances and visionary perspectives, fostering interdisciplinary solutions applicable to domains such as autonomous systems, AR/VR, intelligent robotics, medical diagnostics, and remote sensing. By integrating diverse expertise, HD-Vision seeks to catalyze the next generation of high-dimensional multimedia understanding.
        </p>
    </section>


    <!-- Call for Papers Section -->
    <section id="Call For Paper">
      <h2>Call for Papers</h2>
      <p>We invite original submissions that address challenges and advances across the full spectrum of high-dimensional multimedia understanding. Topics of interest include, but are not limited to:</p>

      <ul>
        <li><b>High-Dimensional Visual Sensing and Computational Imaging</b><br>
          Techniques for capturing complex modalities such as light fields, event-based data, hyperspectral imaging, and multimodal sensor systems.
        </li>
        <li><b>Compression and Neural Representations for Complex Modalities</b><br>
          Efficient encoding, representation, and transmission methods, including learning-based codecs, neural implicit representations, NeRFs, and Gaussian splatting.
        </li>
        <li><b>Semantic Understanding and Cross-Modal Perception</b><br>
          High-level interpretation of spatial, temporal, and angular information, including multi-modal data registration, fusion, and semantic parsing.
        </li>
        <li><b>Vision-Language Reasoning for Multi-modal Data</b><br>
          Foundation models and LLMs for spatially grounded multimodal reasoning, including pretraining strategies, parameter-efficient adaptation, and cross-modal alignment.
        </li>
        <li><b>Datasets and Benchmarks for High-Dimensional Media</b><br>
          Construction, annotation, and evaluation of datasets spanning novel sensing modalities and complex data distributions.
        </li>
        <li><b>Trustworthy and Efficient Multi-modal Intelligence</b><br>
          Energy-aware, robust, and privacy-preserving systems for high-dimensional data processing, including ethical concerns and deployment efficiency on edge devices.
        </li>
      </ul>

        <!-- Submission Links -->
      <p><b>Submission Website:</b> 
        <a href="https://cmt3.research.microsoft.com/MMAsia2025" target="_blank">
          Submit via CMT
        </a>
      </p>
      <p><b>Download CFP (PDF):</b> 
        <a href="assets/pdfs/CFP.pdf" target="_blank">
          Click here to download
        </a>
      </p>
      <p><b>Important Registration Note:</b>  
        All accepted papers need to be covered by a 
        <span style="color: red; font-weight: bold;">full registration</span>.  
        <a href="https://mmasia2025.org/" target="_blank">Click here to register</a>.
      </p>
    </section>

    <!-- Speakers Section -->
    <section id="speakers">
      <h2>Keynote Speaker</h2>
      <div class="speaker-grid">
        <div class="speaker">
          <img src="assets/imgs/avatar_speaker_yiping.jpg" alt="Yi-Ping">
          <h3>Prof. Yi-Ping Phoebe Chen</h3>
          <p>(La Trobe University, Australia)</p>
        </div>
      </div>
    </section>


    <!-- Speakers Section -->
    <section id="speakers">
      <h2>Speakers</h2>
      <div class="speaker-grid">
        <div class="speaker">
          <img src="assets/imgs/avatar_speaker_shiyuxuan.jpg" alt="Shiyu Xuan">
          <h3>Prof. Shiyu Xuan</h3>
          <p>(NJUST, China)</p>
        </div>
        <div class="speaker">
          <img src="assets/imgs/avatar_speaker_hanyuzhou.jpg" alt="Hanyu Zhou">
          <h3>Dr. Hanyu Zhou</h3>
          <p>(NUS, Singapore)</p>
        </div>
        <div class="speaker">
          <img src="assets/imgs/avatar_speaker_zixiangzhao.jpg" alt="Zixiang Zhao">
          <h3>Dr. Zixiang Zhao</h3>
          <p>(ETH Zürich, Switzerland)</p>
        </div>
      </div>
    </section>

    <!-- Schedule Section -->
    <section id="schedule">
      <h2>Schedule</h2>
      TBA
      <!-- <p><b><em>Note: The schedule is for reference only and is subject to change.</em></b></p> -->
      <!-- <table>
        <tr>
          <th>Time</th>
          <th>Event</th>
        </tr>
        <tr>
          <td>08:45 - 09:00</td>
          <td>Welcome &amp; Intro</td>
        </tr>
        <tr>
          <td>09:00 - 09:30</td>
          <td>Invite Talk #1 (Prof. Michael J. Black): <a href="https://youtu.be/_cMRL_i5VmU">Estimating human motion in world coordinates</a></td>
        </tr>
        <tr>
          <td>09:30 - 10:00</td>
          <td>Invite Talk #2 (Prof. Hanbyul Joo): <a href="https://youtu.be/QG-neoiKHvc">Understanding 3D Humans in Contextual 3D Spaces</a></td>
        </tr>
        <tr>
          <td>10:00 - 10:30</td>
          <td>Winner Talks</td>
        </tr>
        <tr>
          <td>10:30 - 11:00</td>
          <td>Breaks</td>
        </tr>
        <tr>
          <td>11:00 - 11:30</td>
          <td>Invite Talk #3 (Prof. Kris Kitani): Modeling Interacting Humans</td>
        </tr>
        <tr>
          <td>11:30 - 12:00</td>
          <td>Invite Talk #4 (Prof. Angjoo Kanazawa): <a href="https://youtu.be/ip1qJAc9lag"> How to Train Your Humanoid</a></td>
        </tr>
        <tr>
          <td>12:00 - 12:30</td>
          <td>Closing</td>
        </tr>
      </table> -->
    </section>

    <!-- Global Pose Challenge Section
    <section id="challenge">
      <h2>Global Pose Challenge</h2>
      <h3>Overview</h3>
      <p>
        We also host the competition from the <a href="https://inside.fifa.com/innovation/innovation-programme/skeletal-tracking" target="_blank">FIFA Skeletal Tracking Innovation Programme</a>. It features a public training split along with internally prepared validation and test splits. The challenge aims to advance the state-of-the-art in global pose estimation by evaluating submissions on a realistic and practical setting.
      </p>

      <h3>Results and Solutions</h3>
      <p>
        The challenge has now concluded. We thank all teams for their participation and contributions. You can find the top teams’ solution write-ups below:
      </p>
      <table>
        <thead>
          <tr>
            <th>Team</th>
            <th>Resources</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Team Tim</td>
            <td><a href="assets/pdfs/solution-tim.pdf">Write-up</a> | <a href="assets/pdfs/talk-hj.pdf">Slides</a></td>
          </tr>
          <tr>
            <td>Team mil</td>
            <td><a href="assets/pdfs/solution-mil.pdf">Write-up</a></td>
          </tr>
          <tr>
            <td>Team arturxarles</td>
            <td><a href="assets/pdfs/solution-arturxarles.pdf">Write-up</a></td>
          </tr>
        </tbody>
      </table>
      <h3>Further Details</h3>
      <p>
        For more information about the challenge, please refer to the <a href="https://inside.fifa.com/innovation/innovation-programme/skeletal-tracking" target="_blank">FIFA's Challenge Page</a> for reference.
      </p>
    </section> -->

    <!-- Organizers Section -->
    <section id="organizers">
      <h2>Organizers</h2>
      <div class="organizers-carousel">
        <div class="organizer">
            <img src="assets/imgs/avatar_organizer_1.png"/>
          <h3>Zeyu Xiao</h3>
          <p>NUS, Singapore</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_2.png"/>
          <h3>Zhuoyuan Li</h3>
          <p>USTC, China</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_3.png"/>
          <h3>Xiang Chen</h3>
          <p>NJUST, China &amp; EntroVision</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_4.png"/>
          <h3>Cong Zhang</h3>
          <p>CUHK, HKSAR</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_5.png"/>
          <h3>Hadi Amirpour</h3>
          <p>University of Klagenfurt, Austria</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_6.png"/>
          <h3>Yakun Ju</h3>
          <p>University of Leicester, UK</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_7.png"/>
          <h3>Zhiwei Xiong</h3>
          <p>USTC, China</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_8.png"/>
          <h3>Kin-Man Lam</h3>
          <p>PolyU, HKSAR</p>
        </div>
      </div>
    </section>


    <!-- Contact Section -->
    <section id="sponsors">
      <h2>Sponsors</h2>
        <p>
          This workshop is proudly sponsored by 
          <a href="https://lowlevelcv.com/" target="_blank">EntroVision</a>.
        </p>
    </section>

    <!-- Contact Section -->
    <section id="contact">
      <h2>Contact</h2>
      <p>For further inquiries, please email us at
        <script>
          const u = "zeyuxiao";
          const d = "nus.edu.sg";
          document.write(`<a href="mailto:${u}@${d}">${u}@${d}</a>`);
        </script>.
      </p>
    </section>
  </div>
</body>
</html>
